{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c956511d0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    _min = np.min(x)\n",
    "    _max = np.max(x)\n",
    "    return (x-_min)/(_max-_min)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, *image_shape], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    in_depth = x_tensor.get_shape()[3].value\n",
    "    out_depth = conv_num_outputs\n",
    "    w_shape = [conv_ksize[0], conv_ksize[1], in_depth, out_depth]\n",
    "    weights = tf.Variable(tf.truncated_normal(w_shape, mean=0, stddev=0.01))\n",
    "    \n",
    "    strides = [1, conv_strides[0], conv_strides[1], 1]\n",
    "    padding = 'SAME'\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(out_depth))\n",
    "    \n",
    "    conv = tf.nn.conv2d(x_tensor, weights, strides, padding)\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    conv = tf.nn.relu(conv)\n",
    "    \n",
    "    maxpl_ksize = [1, pool_ksize[0], pool_ksize[1], 1]\n",
    "    maxpl_strides = [1, pool_strides[0], pool_strides[1], 1]\n",
    "    conv = tf.nn.max_pool(conv, ksize=maxpl_ksize, strides=maxpl_strides, padding='SAME')\n",
    "    \n",
    "    return conv \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_size, *img_size = x_tensor.get_shape().as_list() \n",
    "    img_size = img_size[0] * img_size[1] * img_size[2]\n",
    "    return tf.reshape(x_tensor, [-1,  img_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    w_shape = (int(x_tensor.get_shape().as_list()[1]), num_outputs)\n",
    "    w = tf.Variable(tf.truncated_normal(w_shape, mean=0.0, stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor, w), b)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function \n",
    "    w_shape = (int(x_tensor.get_shape().as_list()[1]), num_outputs)\n",
    "    w = tf.Variable(tf.truncated_normal(w_shape, mean=0.0, stddev=0.1))\n",
    "    b = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor, w), b)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, \n",
    "    #          conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, 32, [3,3], [1,1], [2,2], [2,2])\n",
    "    conv = conv2d_maxpool(conv, 64, [3,3], [1,1], [2,2], [2,2])\n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    conv = conv2d_maxpool(conv, 128, [3,3], [1,1], [2,2], [2,2])\n",
    "    conv = conv2d_maxpool(conv, 256, [3,3], [1,1], [2,2], [2,2])\n",
    "    conv = tf.nn.dropout(conv, keep_prob)\n",
    "    \n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(conv)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    full = fully_conn(flat, 64)\n",
    "    full = fully_conn(full, 32)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(full, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    print('Loss: {:>10.4f} Vallidaction Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 70\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1509 Vallidaction Accuracy: 0.225000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.0186 Vallidaction Accuracy: 0.275000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.9966 Vallidaction Accuracy: 0.300000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.9980 Vallidaction Accuracy: 0.325000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9325 Vallidaction Accuracy: 0.400000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.8256 Vallidaction Accuracy: 0.400000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.7422 Vallidaction Accuracy: 0.425000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.6719 Vallidaction Accuracy: 0.425000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.6577 Vallidaction Accuracy: 0.425000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.6225 Vallidaction Accuracy: 0.450000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.5431 Vallidaction Accuracy: 0.450000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.5076 Vallidaction Accuracy: 0.475000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.5195 Vallidaction Accuracy: 0.500000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.4352 Vallidaction Accuracy: 0.525000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.3697 Vallidaction Accuracy: 0.500000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.3449 Vallidaction Accuracy: 0.575000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.3021 Vallidaction Accuracy: 0.625000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.2912 Vallidaction Accuracy: 0.550000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.2832 Vallidaction Accuracy: 0.525000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.2517 Vallidaction Accuracy: 0.525000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.1747 Vallidaction Accuracy: 0.575000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.1418 Vallidaction Accuracy: 0.675000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.0747 Vallidaction Accuracy: 0.650000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.0388 Vallidaction Accuracy: 0.650000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.0028 Vallidaction Accuracy: 0.650000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.0257 Vallidaction Accuracy: 0.650000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.8823 Vallidaction Accuracy: 0.650000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.9171 Vallidaction Accuracy: 0.650000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.8742 Vallidaction Accuracy: 0.700000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.8586 Vallidaction Accuracy: 0.675000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.8116 Vallidaction Accuracy: 0.750000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.8135 Vallidaction Accuracy: 0.700000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.7672 Vallidaction Accuracy: 0.750000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.6903 Vallidaction Accuracy: 0.725000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.6496 Vallidaction Accuracy: 0.825000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.6393 Vallidaction Accuracy: 0.800000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.6073 Vallidaction Accuracy: 0.775000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.5488 Vallidaction Accuracy: 0.875000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.6285 Vallidaction Accuracy: 0.825000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.5613 Vallidaction Accuracy: 0.825000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.4925 Vallidaction Accuracy: 0.925000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.4954 Vallidaction Accuracy: 0.900000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.5134 Vallidaction Accuracy: 0.850000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.4481 Vallidaction Accuracy: 0.900000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.4314 Vallidaction Accuracy: 0.900000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.4315 Vallidaction Accuracy: 0.925000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.3925 Vallidaction Accuracy: 0.925000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.4101 Vallidaction Accuracy: 0.875000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.3692 Vallidaction Accuracy: 0.950000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.3471 Vallidaction Accuracy: 0.925000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.3772 Vallidaction Accuracy: 0.950000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.3335 Vallidaction Accuracy: 0.925000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.3685 Vallidaction Accuracy: 0.875000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.3069 Vallidaction Accuracy: 0.950000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.3081 Vallidaction Accuracy: 0.900000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.2265 Vallidaction Accuracy: 0.950000\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.2414 Vallidaction Accuracy: 0.950000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.2747 Vallidaction Accuracy: 0.925000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.2789 Vallidaction Accuracy: 0.925000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.2122 Vallidaction Accuracy: 0.950000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.2049 Vallidaction Accuracy: 0.950000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.2247 Vallidaction Accuracy: 0.975000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.1764 Vallidaction Accuracy: 0.975000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.1684 Vallidaction Accuracy: 0.950000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.1743 Vallidaction Accuracy: 0.950000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.1886 Vallidaction Accuracy: 0.950000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.1699 Vallidaction Accuracy: 0.975000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.1765 Vallidaction Accuracy: 0.975000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.1795 Vallidaction Accuracy: 0.975000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.1614 Vallidaction Accuracy: 0.975000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2394 Vallidaction Accuracy: 0.200000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.1008 Vallidaction Accuracy: 0.225000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.7815 Vallidaction Accuracy: 0.175000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.7478 Vallidaction Accuracy: 0.300000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.8198 Vallidaction Accuracy: 0.375000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.9032 Vallidaction Accuracy: 0.300000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.7208 Vallidaction Accuracy: 0.400000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.3818 Vallidaction Accuracy: 0.475000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.5857 Vallidaction Accuracy: 0.375000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.6822 Vallidaction Accuracy: 0.400000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.6883 Vallidaction Accuracy: 0.500000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.5711 Vallidaction Accuracy: 0.475000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.2969 Vallidaction Accuracy: 0.650000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.4520 Vallidaction Accuracy: 0.400000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.6003 Vallidaction Accuracy: 0.400000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.5192 Vallidaction Accuracy: 0.550000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.4275 Vallidaction Accuracy: 0.450000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.1325 Vallidaction Accuracy: 0.625000\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.3769 Vallidaction Accuracy: 0.450000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.4707 Vallidaction Accuracy: 0.475000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.3823 Vallidaction Accuracy: 0.550000\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.3472 Vallidaction Accuracy: 0.450000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.0613 Vallidaction Accuracy: 0.675000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.2857 Vallidaction Accuracy: 0.500000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.3642 Vallidaction Accuracy: 0.525000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.1948 Vallidaction Accuracy: 0.625000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.2381 Vallidaction Accuracy: 0.450000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.0131 Vallidaction Accuracy: 0.725000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.1707 Vallidaction Accuracy: 0.525000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.2760 Vallidaction Accuracy: 0.575000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.1547 Vallidaction Accuracy: 0.575000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.1729 Vallidaction Accuracy: 0.500000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.8887 Vallidaction Accuracy: 0.725000\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.0865 Vallidaction Accuracy: 0.550000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.1887 Vallidaction Accuracy: 0.525000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.0909 Vallidaction Accuracy: 0.575000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.1979 Vallidaction Accuracy: 0.475000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.8435 Vallidaction Accuracy: 0.800000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.0083 Vallidaction Accuracy: 0.575000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.1210 Vallidaction Accuracy: 0.575000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.0439 Vallidaction Accuracy: 0.600000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.1320 Vallidaction Accuracy: 0.525000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.7988 Vallidaction Accuracy: 0.775000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.9914 Vallidaction Accuracy: 0.600000\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.0741 Vallidaction Accuracy: 0.600000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.9988 Vallidaction Accuracy: 0.625000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.1057 Vallidaction Accuracy: 0.575000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.7722 Vallidaction Accuracy: 0.800000\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.9146 Vallidaction Accuracy: 0.675000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.9641 Vallidaction Accuracy: 0.675000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.9563 Vallidaction Accuracy: 0.675000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.0776 Vallidaction Accuracy: 0.550000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.7120 Vallidaction Accuracy: 0.750000\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.9020 Vallidaction Accuracy: 0.650000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.0381 Vallidaction Accuracy: 0.625000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.8479 Vallidaction Accuracy: 0.650000\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.9876 Vallidaction Accuracy: 0.675000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.6617 Vallidaction Accuracy: 0.825000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.8587 Vallidaction Accuracy: 0.625000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.8850 Vallidaction Accuracy: 0.725000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.8669 Vallidaction Accuracy: 0.675000\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.9602 Vallidaction Accuracy: 0.650000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.5832 Vallidaction Accuracy: 0.850000\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.7956 Vallidaction Accuracy: 0.650000\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.8339 Vallidaction Accuracy: 0.725000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.8503 Vallidaction Accuracy: 0.700000\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.8811 Vallidaction Accuracy: 0.725000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.6222 Vallidaction Accuracy: 0.875000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.7905 Vallidaction Accuracy: 0.725000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.7934 Vallidaction Accuracy: 0.775000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.7903 Vallidaction Accuracy: 0.700000\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.8885 Vallidaction Accuracy: 0.675000\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.5474 Vallidaction Accuracy: 0.825000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.7318 Vallidaction Accuracy: 0.750000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.7240 Vallidaction Accuracy: 0.775000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.7930 Vallidaction Accuracy: 0.750000\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.8847 Vallidaction Accuracy: 0.625000\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.5352 Vallidaction Accuracy: 0.900000\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.7248 Vallidaction Accuracy: 0.775000\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.7145 Vallidaction Accuracy: 0.700000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.7562 Vallidaction Accuracy: 0.700000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.8034 Vallidaction Accuracy: 0.675000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.5118 Vallidaction Accuracy: 0.850000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.6724 Vallidaction Accuracy: 0.725000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.7111 Vallidaction Accuracy: 0.800000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.7472 Vallidaction Accuracy: 0.750000\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.7320 Vallidaction Accuracy: 0.725000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.4738 Vallidaction Accuracy: 0.925000\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.6803 Vallidaction Accuracy: 0.775000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.6570 Vallidaction Accuracy: 0.825000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.7230 Vallidaction Accuracy: 0.725000\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.7014 Vallidaction Accuracy: 0.725000\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.4331 Vallidaction Accuracy: 0.850000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.6557 Vallidaction Accuracy: 0.750000\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.6525 Vallidaction Accuracy: 0.825000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.6911 Vallidaction Accuracy: 0.775000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.6896 Vallidaction Accuracy: 0.750000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.4454 Vallidaction Accuracy: 0.850000\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.5818 Vallidaction Accuracy: 0.775000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.5773 Vallidaction Accuracy: 0.825000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     0.6746 Vallidaction Accuracy: 0.775000\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     0.6412 Vallidaction Accuracy: 0.725000\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     0.4148 Vallidaction Accuracy: 0.925000\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     0.5599 Vallidaction Accuracy: 0.800000\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     0.6496 Vallidaction Accuracy: 0.775000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     0.6204 Vallidaction Accuracy: 0.775000\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     0.6172 Vallidaction Accuracy: 0.825000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     0.4686 Vallidaction Accuracy: 0.850000\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     0.5860 Vallidaction Accuracy: 0.825000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     0.6140 Vallidaction Accuracy: 0.800000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     0.6225 Vallidaction Accuracy: 0.750000\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     0.6537 Vallidaction Accuracy: 0.725000\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     0.4045 Vallidaction Accuracy: 0.925000\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     0.5483 Vallidaction Accuracy: 0.800000\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     0.6042 Vallidaction Accuracy: 0.825000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     0.5725 Vallidaction Accuracy: 0.825000\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     0.6036 Vallidaction Accuracy: 0.800000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     0.3767 Vallidaction Accuracy: 0.875000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     0.5306 Vallidaction Accuracy: 0.875000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     0.6120 Vallidaction Accuracy: 0.825000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     0.5964 Vallidaction Accuracy: 0.825000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     0.6429 Vallidaction Accuracy: 0.750000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     0.3564 Vallidaction Accuracy: 0.925000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     0.4784 Vallidaction Accuracy: 0.875000\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     0.5396 Vallidaction Accuracy: 0.850000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     0.6075 Vallidaction Accuracy: 0.800000\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     0.5735 Vallidaction Accuracy: 0.825000\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     0.3431 Vallidaction Accuracy: 0.925000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     0.5150 Vallidaction Accuracy: 0.800000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     0.5680 Vallidaction Accuracy: 0.850000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     0.5519 Vallidaction Accuracy: 0.850000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     0.5733 Vallidaction Accuracy: 0.875000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     0.3146 Vallidaction Accuracy: 0.900000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     0.4822 Vallidaction Accuracy: 0.875000\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     0.4984 Vallidaction Accuracy: 0.825000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     0.5644 Vallidaction Accuracy: 0.775000\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     0.5737 Vallidaction Accuracy: 0.800000\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     0.3645 Vallidaction Accuracy: 0.900000\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     0.4966 Vallidaction Accuracy: 0.825000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     0.5505 Vallidaction Accuracy: 0.825000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     0.5451 Vallidaction Accuracy: 0.775000\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     0.5272 Vallidaction Accuracy: 0.850000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     0.3148 Vallidaction Accuracy: 0.900000\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     0.4894 Vallidaction Accuracy: 0.900000\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     0.5149 Vallidaction Accuracy: 0.875000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     0.5755 Vallidaction Accuracy: 0.800000\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     0.5205 Vallidaction Accuracy: 0.825000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     0.3319 Vallidaction Accuracy: 0.950000\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     0.4909 Vallidaction Accuracy: 0.850000\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     0.4367 Vallidaction Accuracy: 0.900000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     0.4950 Vallidaction Accuracy: 0.850000\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     0.4833 Vallidaction Accuracy: 0.850000\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     0.2677 Vallidaction Accuracy: 0.950000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     0.4789 Vallidaction Accuracy: 0.825000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     0.4679 Vallidaction Accuracy: 0.925000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     0.5557 Vallidaction Accuracy: 0.800000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     0.5029 Vallidaction Accuracy: 0.850000\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     0.3065 Vallidaction Accuracy: 0.950000\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     0.4554 Vallidaction Accuracy: 0.850000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     0.5081 Vallidaction Accuracy: 0.850000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     0.5178 Vallidaction Accuracy: 0.800000\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     0.4620 Vallidaction Accuracy: 0.825000\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     0.3174 Vallidaction Accuracy: 0.925000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     0.3770 Vallidaction Accuracy: 0.875000\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     0.4461 Vallidaction Accuracy: 0.875000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     0.5603 Vallidaction Accuracy: 0.775000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     0.4752 Vallidaction Accuracy: 0.800000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     0.2650 Vallidaction Accuracy: 0.925000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     0.4563 Vallidaction Accuracy: 0.825000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     0.4280 Vallidaction Accuracy: 0.875000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     0.5361 Vallidaction Accuracy: 0.850000\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     0.4060 Vallidaction Accuracy: 0.875000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     0.2703 Vallidaction Accuracy: 0.925000\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     0.3816 Vallidaction Accuracy: 0.900000\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     0.3904 Vallidaction Accuracy: 0.875000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     0.5103 Vallidaction Accuracy: 0.825000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     0.3574 Vallidaction Accuracy: 0.925000\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     0.2885 Vallidaction Accuracy: 0.950000\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     0.4268 Vallidaction Accuracy: 0.825000\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     0.4267 Vallidaction Accuracy: 0.850000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     0.4925 Vallidaction Accuracy: 0.800000\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     0.3910 Vallidaction Accuracy: 0.850000\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     0.2784 Vallidaction Accuracy: 0.925000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     0.3824 Vallidaction Accuracy: 0.900000\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     0.4076 Vallidaction Accuracy: 0.850000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     0.4520 Vallidaction Accuracy: 0.825000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     0.3494 Vallidaction Accuracy: 0.925000\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     0.2723 Vallidaction Accuracy: 0.950000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     0.3926 Vallidaction Accuracy: 0.875000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     0.3826 Vallidaction Accuracy: 0.875000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     0.4681 Vallidaction Accuracy: 0.775000\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     0.3368 Vallidaction Accuracy: 0.900000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     0.2379 Vallidaction Accuracy: 0.925000\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     0.3834 Vallidaction Accuracy: 0.875000\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     0.3775 Vallidaction Accuracy: 0.900000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     0.4623 Vallidaction Accuracy: 0.825000\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     0.3658 Vallidaction Accuracy: 0.900000\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     0.2571 Vallidaction Accuracy: 0.950000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     0.3931 Vallidaction Accuracy: 0.875000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     0.3634 Vallidaction Accuracy: 0.875000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     0.4470 Vallidaction Accuracy: 0.875000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     0.3447 Vallidaction Accuracy: 0.900000\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     0.2733 Vallidaction Accuracy: 0.950000\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     0.3299 Vallidaction Accuracy: 0.900000\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     0.3205 Vallidaction Accuracy: 0.925000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     0.4528 Vallidaction Accuracy: 0.875000\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     0.3154 Vallidaction Accuracy: 0.900000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     0.2511 Vallidaction Accuracy: 0.925000\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     0.3973 Vallidaction Accuracy: 0.875000\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     0.3801 Vallidaction Accuracy: 0.850000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     0.4154 Vallidaction Accuracy: 0.875000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     0.3328 Vallidaction Accuracy: 0.875000\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     0.2776 Vallidaction Accuracy: 0.925000\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     0.3778 Vallidaction Accuracy: 0.875000\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     0.3414 Vallidaction Accuracy: 0.900000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     0.4249 Vallidaction Accuracy: 0.875000\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     0.3403 Vallidaction Accuracy: 0.875000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     0.2272 Vallidaction Accuracy: 0.950000\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     0.3633 Vallidaction Accuracy: 0.875000\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     0.2871 Vallidaction Accuracy: 0.900000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     0.3927 Vallidaction Accuracy: 0.875000\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     0.3251 Vallidaction Accuracy: 0.900000\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     0.2334 Vallidaction Accuracy: 0.950000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     0.3261 Vallidaction Accuracy: 0.925000\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     0.3022 Vallidaction Accuracy: 0.925000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     0.3484 Vallidaction Accuracy: 0.900000\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     0.2839 Vallidaction Accuracy: 0.975000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     0.2069 Vallidaction Accuracy: 0.925000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     0.3751 Vallidaction Accuracy: 0.850000\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     0.2952 Vallidaction Accuracy: 0.925000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     0.4107 Vallidaction Accuracy: 0.850000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     0.2772 Vallidaction Accuracy: 0.925000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     0.2206 Vallidaction Accuracy: 0.900000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     0.3759 Vallidaction Accuracy: 0.925000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     0.3266 Vallidaction Accuracy: 0.925000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     0.3681 Vallidaction Accuracy: 0.900000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     0.2557 Vallidaction Accuracy: 0.975000\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     0.1988 Vallidaction Accuracy: 0.950000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     0.3329 Vallidaction Accuracy: 0.900000\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     0.3124 Vallidaction Accuracy: 0.875000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     0.4023 Vallidaction Accuracy: 0.875000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     0.3117 Vallidaction Accuracy: 0.875000\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     0.2278 Vallidaction Accuracy: 0.925000\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     0.3473 Vallidaction Accuracy: 0.900000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     0.2981 Vallidaction Accuracy: 0.875000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     0.4024 Vallidaction Accuracy: 0.875000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     0.2484 Vallidaction Accuracy: 0.975000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     0.2064 Vallidaction Accuracy: 0.925000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     0.3224 Vallidaction Accuracy: 0.900000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     0.2731 Vallidaction Accuracy: 0.950000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     0.3786 Vallidaction Accuracy: 0.900000\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     0.2304 Vallidaction Accuracy: 0.950000\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     0.2119 Vallidaction Accuracy: 0.925000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     0.3212 Vallidaction Accuracy: 0.925000\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     0.3084 Vallidaction Accuracy: 0.925000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     0.3819 Vallidaction Accuracy: 0.875000\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     0.2871 Vallidaction Accuracy: 0.900000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     0.2385 Vallidaction Accuracy: 0.950000\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     0.3774 Vallidaction Accuracy: 0.900000\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     0.2907 Vallidaction Accuracy: 0.925000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     0.3969 Vallidaction Accuracy: 0.800000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     0.2347 Vallidaction Accuracy: 0.975000\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     0.2131 Vallidaction Accuracy: 0.900000\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     0.3241 Vallidaction Accuracy: 0.900000\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     0.3200 Vallidaction Accuracy: 0.900000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     0.3710 Vallidaction Accuracy: 0.900000\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     0.2252 Vallidaction Accuracy: 0.950000\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     0.1787 Vallidaction Accuracy: 0.925000\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     0.3023 Vallidaction Accuracy: 0.925000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     0.3071 Vallidaction Accuracy: 0.900000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     0.3822 Vallidaction Accuracy: 0.900000\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     0.2411 Vallidaction Accuracy: 0.925000\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     0.2206 Vallidaction Accuracy: 0.925000\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     0.2926 Vallidaction Accuracy: 0.925000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     0.2635 Vallidaction Accuracy: 0.950000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     0.3949 Vallidaction Accuracy: 0.875000\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     0.2012 Vallidaction Accuracy: 0.950000\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     0.2216 Vallidaction Accuracy: 0.900000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     0.3263 Vallidaction Accuracy: 0.925000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     0.2922 Vallidaction Accuracy: 0.925000\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     0.3613 Vallidaction Accuracy: 0.825000\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     0.2418 Vallidaction Accuracy: 0.950000\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     0.2174 Vallidaction Accuracy: 0.925000\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     0.2836 Vallidaction Accuracy: 0.925000\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     0.3015 Vallidaction Accuracy: 0.900000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     0.3425 Vallidaction Accuracy: 0.875000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     0.2261 Vallidaction Accuracy: 1.000000\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     0.2016 Vallidaction Accuracy: 0.950000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     0.2713 Vallidaction Accuracy: 0.925000\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     0.2480 Vallidaction Accuracy: 0.925000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     0.3336 Vallidaction Accuracy: 0.900000\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     0.2573 Vallidaction Accuracy: 0.950000\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     0.1675 Vallidaction Accuracy: 0.925000\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     0.2665 Vallidaction Accuracy: 0.950000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     0.2664 Vallidaction Accuracy: 0.975000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     0.3439 Vallidaction Accuracy: 0.900000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     0.1883 Vallidaction Accuracy: 0.975000\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     0.1843 Vallidaction Accuracy: 0.925000\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     0.2438 Vallidaction Accuracy: 0.925000\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     0.2601 Vallidaction Accuracy: 0.925000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     0.3512 Vallidaction Accuracy: 0.925000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     0.1792 Vallidaction Accuracy: 1.000000\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     0.1523 Vallidaction Accuracy: 0.950000\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     0.2978 Vallidaction Accuracy: 0.900000\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     0.2483 Vallidaction Accuracy: 0.925000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     0.3131 Vallidaction Accuracy: 0.950000\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     0.2546 Vallidaction Accuracy: 0.925000\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     0.2043 Vallidaction Accuracy: 0.950000\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     0.2703 Vallidaction Accuracy: 0.900000\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     0.2472 Vallidaction Accuracy: 0.925000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     0.3568 Vallidaction Accuracy: 0.875000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     0.2106 Vallidaction Accuracy: 0.925000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     0.1794 Vallidaction Accuracy: 0.925000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     0.2011 Vallidaction Accuracy: 0.950000\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     0.2217 Vallidaction Accuracy: 0.975000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     0.3492 Vallidaction Accuracy: 0.900000\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     0.1861 Vallidaction Accuracy: 0.950000\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     0.1760 Vallidaction Accuracy: 0.950000\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     0.2451 Vallidaction Accuracy: 0.975000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     0.2483 Vallidaction Accuracy: 0.925000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     0.3297 Vallidaction Accuracy: 0.925000\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     0.1869 Vallidaction Accuracy: 0.975000\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     0.1984 Vallidaction Accuracy: 0.925000\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     0.2213 Vallidaction Accuracy: 0.925000\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     0.2462 Vallidaction Accuracy: 0.975000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     0.3082 Vallidaction Accuracy: 0.950000\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     0.1876 Vallidaction Accuracy: 1.000000\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     0.2085 Vallidaction Accuracy: 0.925000\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     0.2285 Vallidaction Accuracy: 0.925000\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     0.2468 Vallidaction Accuracy: 0.950000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     0.3055 Vallidaction Accuracy: 0.900000\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     0.1755 Vallidaction Accuracy: 0.975000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     0.1832 Vallidaction Accuracy: 0.925000\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     0.2533 Vallidaction Accuracy: 0.925000\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     0.2182 Vallidaction Accuracy: 0.950000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     0.3356 Vallidaction Accuracy: 0.850000\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     0.1796 Vallidaction Accuracy: 0.975000\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     0.1855 Vallidaction Accuracy: 0.925000\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     0.2151 Vallidaction Accuracy: 0.950000\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     0.2349 Vallidaction Accuracy: 0.975000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     0.3011 Vallidaction Accuracy: 0.900000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     0.1659 Vallidaction Accuracy: 1.000000\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     0.1683 Vallidaction Accuracy: 0.925000\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     0.2344 Vallidaction Accuracy: 0.925000\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     0.2089 Vallidaction Accuracy: 0.950000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     0.2757 Vallidaction Accuracy: 0.925000\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     0.1897 Vallidaction Accuracy: 1.000000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     0.1580 Vallidaction Accuracy: 0.950000\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     0.2427 Vallidaction Accuracy: 0.950000\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     0.2518 Vallidaction Accuracy: 0.900000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7552412974683544\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYxERERGRSMGxiIiIiEik4FhEREREJPr/gbZAhttolqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5cfb096ef0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
